{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset -fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(filepath,ml):\n",
    "    c = []\n",
    "    if ml == 0:\n",
    "        ml = 1000\n",
    "    with open(filepath,'r') as f:\n",
    "        for line in f:\n",
    "            line = line.replace('\\n','')\n",
    "            s = 0\n",
    "            c.append([int(line.split()[i]) for i in range(len(line.split())) if i<ml])\n",
    "    return c\n",
    "\n",
    "def final_preprocess(c):   #padding\n",
    "    max_l = max([len(i) for i in c])\n",
    "    for i in range(len(c)):\n",
    "        c[i] = c[i] + (max_l-len(c[i]))*[0]\n",
    "    return c,max_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading train data and preprocessing them + padding\n",
    "#pad the context and question data\n",
    "context_data,max_l_context = final_preprocess(preprocess('data/train.ids.context',600))\n",
    "question_data,max_l_question = final_preprocess(preprocess('data/train.ids.question',0))\n",
    "answer_data = preprocess('data/train.span',0)\n",
    "answer_start_data = [i[0] for i in answer_data]\n",
    "answer_end_data = [i[1] for i in answer_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/train.ids.question', 'r') as f:\n",
    "    result = []\n",
    "    for line in f:\n",
    "        result.append(len(line.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,u'count')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEKCAYAAADaa8itAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUJEkdcZQkSR1xlCRJHXGUJEkdeb/A7hLBt6I4vBKAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116373a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(data=result).hist(bins=50)\n",
    "plt.xlabel('length')\n",
    "plt.ylabel('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(question_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "print max_l_context\n",
    "print max_l_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def length(sequence):\n",
    "    used = tf.sign(tf.reduce_max(tf.abs(sequence), axis=2))\n",
    "    length = tf.reduce_sum(used, axis=1)\n",
    "    length = tf.cast(length, tf.int32)\n",
    "    #print \"sequence length tf shape:\",length.shape\n",
    "    return length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder function\n",
    "def encoder(question,context,embeddings,hidden_units=200):\n",
    "    batch_size = tf.shape(question)[0]\n",
    "    #question and document encoder\n",
    "    q_embedding = tf.nn.embedding_lookup(embeddings,question)\n",
    "    d_embedding = tf.nn.embedding_lookup(embeddings,context)\n",
    "    \n",
    "    print q_embedding.shape,\"=?,60,100\"\n",
    "    print d_embedding.shape,\"=?,600,100\"\n",
    "    \n",
    "    lstm_enc = tf.contrib.rnn.BasicLSTMCell(hidden_units)\n",
    "    \n",
    "    with tf.variable_scope('document_encoder') as scope1:\n",
    "        document_states,_ = tf.nn.dynamic_rnn(cell=lstm_enc,\n",
    "                                              dtype=tf.float32,\n",
    "                                              inputs=d_embedding,\n",
    "                                              sequence_length=length(q_embedding),\n",
    "                                              time_major=False)\n",
    "        \n",
    "    with tf.variable_scope('question_encoder') as scope2:\n",
    "        question_states,_ = tf.nn.dynamic_rnn(cell=lstm_enc,\n",
    "                                              dtype=tf.float32,\n",
    "                                              inputs=q_embedding,\n",
    "                                              sequence_length=length(d_embedding),\n",
    "                                              time_major=False)\n",
    "\n",
    "    Wq = tf.get_variable(name=\"Wq\",shape=[hidden_units,hidden_units],initializer=tf.contrib.layers.xavier_initializer(),dtype=tf.float32)\n",
    "    bq = tf.Variable(tf.constant(0.0,shape=[hidden_units,]),dtype=tf.float32,name='bq')\n",
    "    Wq = tf.expand_dims(tf.ones([batch_size,1]), 1) * Wq\n",
    "    #question_states_new = tf.reshape(question_states,shape=[-1,hidden_units])\n",
    "    print document_states.shape,\"=?,600,200\"\n",
    "    print question_states.shape,\"=?,60,200\"\n",
    "    #print question_states_new.shape,\"=?,200\"\n",
    "    print Wq.shape,\"=?,200,200\"\n",
    "    print bq.shape,\"=200,\"\n",
    "    \n",
    "                    \n",
    "    question_states_modified_duplicate = tf.nn.tanh(tf.matmul(question_states,Wq)+bq)\n",
    "    #question_states_modified_duplicate = tf.reshape(question_states_modified,shape=[-1,int(question_states.shape[1]),hidden_units])\n",
    "    question_states_modified = tf.transpose(question_states_modified_duplicate,perm=[0,2,1]) #tf.reshape(question_states_modified,shape=[-1,hidden_units,int(question_states.shape[1])])\n",
    "    print question_states_modified.shape,\"=?,200,60\"\n",
    "    print question_states_modified_duplicate.shape,\"=?,60,200\"\n",
    "\n",
    "    #coattention encoder\n",
    "    \n",
    "    l = tf.matmul(document_states,question_states_modified)\n",
    "    print l.shape,\"=?,600,60\"\n",
    "    aq = tf.nn.softmax(l)\n",
    "    ad = tf.nn.softmax(tf.transpose(l,perm=[0, 2, 1]))\n",
    "    print aq.shape,\"=?,600,60\"\n",
    "    print ad.shape,\"=?,60,600\"\n",
    "    \n",
    "    cq = tf.matmul(tf.transpose(aq,perm=[0,2,1]),document_states)\n",
    "    print cq.shape,\"=?,60,200\"\n",
    "    print question_states_modified_duplicate.shape,\"=?,60,200\"\n",
    "    qcq = tf.concat([question_states_modified_duplicate,cq],2)\n",
    "    print qcq.shape,\"=?,60,400\"\n",
    "    cd = tf.matmul(tf.transpose(ad,perm=[0,2,1]),qcq)\n",
    "    print cd.shape,\"=?,600,400\"\n",
    "    dcd = tf.concat([document_states,cd],axis=2)\n",
    "    print dcd.shape,\"=?,600,600\"\n",
    "    \n",
    "    with tf.variable_scope('coattention'):\n",
    "        u_lstm_fw = tf.contrib.rnn.BasicLSTMCell(hidden_units)  #bi-lstm\n",
    "        u_lstm_bw = tf.contrib.rnn.BasicLSTMCell(hidden_units)\n",
    "        u_states,_ = tf.nn.bidirectional_dynamic_rnn(cell_bw=u_lstm_bw,cell_fw=u_lstm_fw,dtype=tf.float32,inputs=dcd,time_major=False,sequence_length=length(dcd))\n",
    "    encoder_states = tf.concat(u_states,2)\n",
    "    print encoder_states.shape\n",
    "    return encoder_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decoder function\n",
    "def decoder(knowledge_reps,hidden_units = 200):\n",
    "    #randomly initialise s and e\n",
    "    batch_size = tf.shape(knowledge_reps)[0]\n",
    "    #print batch_size\n",
    "    pool = 16\n",
    "    e = np.random.randint(max_l_context) + 1\n",
    "    s = np.random.randint(e)\n",
    "    sv = tf.tile([s],[batch_size])\n",
    "    ev = tf.tile([e],[batch_size])\n",
    "\n",
    "    #lstm cell\n",
    "    #with tf.variable_scope('lstm_dec') as scope_dec:\n",
    "    lstm_dec = tf.contrib.rnn.LSTMCell(hidden_units)\n",
    "    ch = lstm_dec.zero_state(batch_size,dtype=tf.float32)\n",
    "    hi,ci = ch\n",
    "    \n",
    "    \n",
    "    with tf.variable_scope('hmn1') as scope1:\n",
    "        wd = tf.get_variable(name=\"wd\",shape=[hidden_units,5*hidden_units],initializer=tf.contrib.layers.xavier_initializer(),dtype=tf.float32)\n",
    "        w1 = tf.get_variable(name=\"w1\",shape=[pool*hidden_units,3*hidden_units],initializer=tf.contrib.layers.xavier_initializer(),dtype=tf.float32)\n",
    "        w2 = tf.get_variable(name=\"w2\",shape=[pool*hidden_units,hidden_units],initializer=tf.contrib.layers.xavier_initializer(),dtype=tf.float32)\n",
    "        w3 = tf.get_variable(name=\"w3\",shape=[pool,2*hidden_units],initializer=tf.contrib.layers.xavier_initializer(),dtype=tf.float32)\n",
    "    \n",
    "    with tf.variable_scope('hmn2') as scope2:\n",
    "        wd = tf.get_variable(name=\"wd\",shape=[hidden_units,5*hidden_units],initializer=tf.contrib.layers.xavier_initializer(),dtype=tf.float32)\n",
    "        w1 = tf.get_variable(name=\"w1\",shape=[pool*hidden_units,3*hidden_units],initializer=tf.contrib.layers.xavier_initializer(),dtype=tf.float32)\n",
    "        w2 = tf.get_variable(name=\"w2\",shape=[pool*hidden_units,hidden_units],initializer=tf.contrib.layers.xavier_initializer(),dtype=tf.float32)\n",
    "        w3 = tf.get_variable(name=\"w3\",shape=[pool,2*hidden_units],initializer=tf.contrib.layers.xavier_initializer(),dtype=tf.float32)\n",
    "\n",
    "        \n",
    "    #loop 4 times to call lstm cell to:\n",
    "    for i in range(4):\n",
    "        #concatenate u_s and u_e\n",
    "        u_s = tf.gather_nd(params=knowledge_reps,indices=tf.stack([tf.range(batch_size,dtype=tf.int32),sv],axis=1))\n",
    "        u_e = tf.gather_nd(params=knowledge_reps,indices=tf.stack([tf.range(batch_size,dtype=tf.int32),ev],axis=1))\n",
    "        usue = tf.concat([u_s,u_e],axis=1)\n",
    "        print i,usue.shape,hi.shape\n",
    "        #calculate hi\n",
    "         \n",
    "        with tf.variable_scope(\"hmn1\",reuse=True) as scope1:\n",
    "            sv,hmns_output = hmn(knowledge_reps,hi,u_s,u_e,hidden_units,pool)#loop over the document length times to obtain alpha t using HNM function\n",
    "        with tf.variable_scope(\"hmn2\",reuse=True) as scope2:\n",
    "            ev,hmne_output = hmn(knowledge_reps,hi,u_s,u_e,hidden_units,pool)#loop over the document length times to obtain beta t using HNM function\n",
    "        \n",
    "        hi,ch = lstm_dec(inputs=usue,state=ch) \n",
    "        \n",
    "    return sv,ev,hmns_output,hmne_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hmn(kr,hs,us,ue,hidden_units,pool=16):\n",
    "    \n",
    "    #print \"kr\",kr.shape\n",
    "    #calculate r\n",
    "    wd = tf.get_variable(name=\"wd\",shape=[hidden_units,5*hidden_units],initializer=tf.contrib.layers.xavier_initializer(),dtype=tf.float32)\n",
    "    x = tf.concat([hs,us,ue],axis=1)\n",
    "    r = tf.nn.tanh(tf.matmul(x,tf.transpose(wd)))\n",
    "    #print r.shape\n",
    "\n",
    "    #calculate mt1\n",
    "    r1 = tf.expand_dims(tf.ones([int(kr.shape[1]),1]), 1) * r\n",
    "    r1 = tf.reshape(r1,[-1,hidden_units])\n",
    "    kr1 = tf.reshape(kr,[-1,2*hidden_units])\n",
    "    krr1 = tf.concat([kr1,r1],axis=1)\n",
    "    w1 = tf.get_variable(name=\"w1\",shape=[pool*hidden_units,3*hidden_units],initializer=tf.contrib.layers.xavier_initializer(),dtype=tf.float32)\n",
    "    b1 = tf.Variable(tf.constant(0.0,shape=[pool*hidden_units,]),dtype=tf.float32)\n",
    "    x1 = tf.matmul(krr1,tf.transpose(w1))+b1\n",
    "    x1 = tf.reshape(x1,[-1,pool])\n",
    "    x1 = tf.reduce_max(x1,axis=1)\n",
    "    m1 = tf.reshape(x1,[-1,hidden_units])\n",
    "    #print m1.shape\n",
    "    \n",
    "    #calculate mt2\n",
    "    w2 = tf.get_variable(name=\"w2\",shape=[pool*hidden_units,hidden_units],initializer=tf.contrib.layers.xavier_initializer(),dtype=tf.float32)\n",
    "    b2 = tf.Variable(tf.constant(0.0,shape=[pool*hidden_units,]),dtype=tf.float32)\n",
    "    x2 = tf.matmul(m1,tf.transpose(w2))+b2\n",
    "    x2 = tf.reshape(x2,[-1,pool])\n",
    "    x2 = tf.reduce_max(x2,axis=1)\n",
    "    m2 = tf.reshape(x2,[-1,hidden_units])\n",
    "    #print m2.shape\n",
    "    \n",
    "    #max\n",
    "    m1m2 = tf.concat([m1,m2],axis=1)\n",
    "    #print \"m1m2\",m1m2.shape\n",
    "    w3 = tf.get_variable(name=\"w3\",shape=[pool,2*hidden_units],initializer=tf.contrib.layers.xavier_initializer(),dtype=tf.float32)\n",
    "    b3 = tf.Variable(tf.constant(0.0,shape=[pool,]),dtype=tf.float32)\n",
    "    x3 = tf.matmul(m1m2,tf.transpose(w3))+b3\n",
    "    #print x3.shape\n",
    "    x3 = tf.reduce_max(x3,axis=1)\n",
    "    #print x3.shape\n",
    "    x3 = tf.reshape(x3,[-1,int(kr.shape[1])])\n",
    "    #print \"x3\",x3.shape\n",
    "    #argmax\n",
    "    output = tf.argmax(x3,axis=1)\n",
    "    output = tf.cast(output,dtype=tf.int32)\n",
    "    \n",
    "    return output,x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read embedding file\n",
    "embedding_array = np.load('data/glove.trimmed.100.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.52058829, -0.51654186,  0.27968494, -1.81354095, -0.24410476,\n",
       "       -0.68052369, -0.00260126, -1.15966041,  0.13565797, -2.03933159,\n",
       "        1.39574077, -0.41010746,  0.78249643, -0.03234985,  1.49243316,\n",
       "        0.58828367, -0.12553187,  2.22018055, -0.45500756,  0.89039387,\n",
       "       -0.18749341,  0.1809392 ,  0.29886465, -0.24914736, -0.49023885,\n",
       "       -1.01622756,  1.8752643 ,  0.44214767,  1.33379188, -1.34961692,\n",
       "       -0.01415288, -0.59999874, -0.81665375,  2.37627875, -0.4235163 ,\n",
       "        0.57595554,  0.59935966,  0.02639429, -0.26178128,  0.4963044 ,\n",
       "        1.88299358, -0.46125415,  0.6598317 ,  2.18697996, -1.18201243,\n",
       "       -1.56485642,  0.71330753,  0.43130444,  0.24754809,  1.52875936,\n",
       "        0.12049194,  1.81434007,  0.11948352, -0.17062094,  0.26578507,\n",
       "       -0.38349847,  1.14144629,  1.74730465,  0.12359092, -0.68782479,\n",
       "       -0.71124553,  0.11059589, -1.03285808,  0.62593014, -0.68293404,\n",
       "        0.45794549, -1.84091036,  1.27705293, -0.24747408,  0.10791822,\n",
       "        0.74738734,  0.33532065, -0.21005892,  0.52853634, -1.82094303,\n",
       "       -0.29553369,  1.88826883,  1.41438938,  1.16707241,  1.24758589,\n",
       "        0.10214536, -0.44961063,  1.78224884, -0.85140106, -0.6694391 ,\n",
       "        0.7387805 , -2.2642288 , -1.09590889,  1.15175444,  0.49601925,\n",
       "       -1.26474121,  0.74908335,  0.39721525, -0.68880461, -0.10933572,\n",
       "        0.31228823,  2.57939613, -0.1654663 ,  0.17701885,  2.5159267 ])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_array['glove'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 60, 100) =?,60,100\n",
      "(?, 600, 100) =?,600,100\n",
      "(?, 600, 200) =?,600,200\n",
      "(?, 60, 200) =?,60,200\n",
      "(?, 200, 200) =?,200,200\n",
      "(200,) =200,\n",
      "(?, 200, 60) =?,200,60\n",
      "(?, 60, 200) =?,60,200\n",
      "(?, 600, 60) =?,600,60\n",
      "(?, 600, 60) =?,600,60\n",
      "(?, 60, 600) =?,60,600\n",
      "(?, 60, 200) =?,60,200\n",
      "(?, 60, 200) =?,60,200\n",
      "(?, 60, 400) =?,60,400\n",
      "(?, 600, 400) =?,600,400\n",
      "(?, 600, 600) =?,600,600\n",
      "(?, 600, 400)\n",
      "decoder starts\n",
      "0 (?, 800) (?, 200)\n",
      "1 (?, 800) (?, 200)\n",
      "2 (?, 800) (?, 200)\n",
      "3 (?, 800) (?, 200)\n"
     ]
    }
   ],
   "source": [
    "## create placeholders\n",
    "tf.reset_default_graph()\n",
    "hidden_units = 200\n",
    "question = tf.placeholder(dtype=tf.int32,shape=[None,max_l_question])\n",
    "context = tf.placeholder(dtype=tf.int32,shape=[None,max_l_context])\n",
    "answer_start = tf.placeholder(dtype=tf.int32,shape=[None])\n",
    "answer_end = tf.placeholder(dtype=tf.int32,shape=[None])\n",
    "embeddings = tf.constant(embedding_array['glove'],dtype=tf.float32)\n",
    "\n",
    "encoder_states = encoder(question,context,embeddings)\n",
    "print \"decoder starts\"\n",
    "decoder_output_start, decoder_output_end, hmns_output, hmne_output = decoder(encoder_states)\n",
    "\n",
    "## add loss\n",
    "l1 = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=answer_start,logits=hmns_output)\n",
    "l2 = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=answer_end,logits=hmne_output)\n",
    "loss = l1 + l2\n",
    "\n",
    "# print \"hmns_output.shape: \",hmns_output.shape\n",
    "# ## EM accuracy\n",
    "pred_start = tf.argmax(hmns_output, 1)\n",
    "# pred_start_v = tf.expand_dims(pred_start, 1)\n",
    "pred_end = tf.argmax(hmne_output, 1)\n",
    "# pred_end_v = tf.expand_dims(pred_end, 1)\n",
    "# pred = tf.gather_nd(question, )\n",
    "\n",
    "# answer_start_v = tf.expand_dims(answer_start, 1)\n",
    "# answer_end_v = tf.expand_dims(answer_end, 1)\n",
    "\n",
    "# print \"question.shape: \",question.shape\n",
    "# print \"pred_start.shape: \",pred_start.shape\n",
    "# print \"answers.shape\",tf.gather_nd(question, answer_start_v).shape\n",
    "# print \"tf.equal shape: \",tf.equal(tf.gather_nd(context, pred_start_v), tf.gather_nd(context, answer_start_v)).shape\n",
    "# EM_acc = tf.logical_and(tf.equal(tf.gather_nd(context, pred_start_v), tf.gather_nd(context, answer_start_v)), \n",
    "#                         tf.equal(tf.gather_nd(context, pred_end_v), tf.gather_nd(context, answer_end_v))\n",
    "#                        )\n",
    "# EM_acc = tf.cast(EM_acc, tf.int32)\n",
    "# EM_acc = tf.reduce_mean(tf.reduce_min(EM_acc, axis=1))\n",
    "# print \"EM_acc.shape: \",EM_acc.shape\n",
    "\n",
    "## F1 Score\n",
    "\n",
    "\n",
    "## add optimizer\n",
    "train_op = tf.train.AdamOptimizer(0.0001).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialise variables and train\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step =  0\n",
      "F1 Score =  0.00827312367983\n",
      "step =  1\n",
      "F1 Score =  0.0291399243518\n",
      "step =  2\n",
      "F1 Score =  0.0281360280444\n",
      "step =  3\n",
      "F1 Score =  0.0338071461735\n",
      "step =  4\n",
      "F1 Score =  0.0305646808374\n",
      "step =  5\n",
      "F1 Score =  0.0265996723329\n",
      "step =  6\n",
      "F1 Score =  0.0258803632207\n",
      "step =  7\n",
      "F1 Score =  0.0203915550595\n",
      "step =  8\n",
      "F1 Score =  0.0206473214286\n",
      "step =  9\n",
      "F1 Score =  0.0426070268497\n",
      "step =  10\n",
      "F1 Score =  0.0302786759129\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-3d30ae90f4cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0manswer_end_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer_end_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_start_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_end_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_end\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mquestion\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mquestion_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mcontext_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswer_start\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0manswer_start_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswer_end\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0manswer_end_batch\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_start_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpred_end_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswer_start_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswer_end_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;32mprint\u001b[0m \u001b[0;34m\"step = \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tiantri/anaconda/envs/nlp-final/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tiantri/anaconda/envs/nlp-final/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tiantri/anaconda/envs/nlp-final/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tiantri/anaconda/envs/nlp-final/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tiantri/anaconda/envs/nlp-final/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#session run train\n",
    "validation_size = 1000\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    batch_size = 128\n",
    "    for epocs in range(100):\n",
    "        counter = 0\n",
    "        for steps in range(318):\n",
    "            question_batch = np.array(question_data[counter:(counter+batch_size)])\n",
    "            context_batch = np.array(context_data[counter:(counter+batch_size)])\n",
    "            answer_start_batch = np.array(answer_start_data[counter:(counter+batch_size)])\n",
    "            answer_end_batch = np.array(answer_end_data[counter:(counter+batch_size)])\n",
    "            \n",
    "            _, pred_start_batch, pred_end_batch = sess.run([train_op, pred_start, pred_end], feed_dict = {question : question_batch, context : context_batch, answer_start : answer_start_batch, answer_end : answer_end_batch})\n",
    "            f1, em = evaluate(context_batch, pred_start_batch,pred_end_batch, answer_start_batch, answer_end_batch)\n",
    "            print \"=\" * 20\n",
    "            print \"step = \", steps\n",
    "            print \"F1 Score = \", f1\n",
    "            print \"EM score = \", em\n",
    "                \n",
    "            if steps % 100 == 0:\n",
    "                Q_val = np.array(question_data[-validation_size:])\n",
    "                D_val = np.array(context_data[-validation_size:])\n",
    "                A_start = np.array(answer_start_data[-validation_size:])\n",
    "                A_end = np.array(answer_end_data[-validation_size:])\n",
    "                loss_val, pred_start_val, pred_end_val, true_start_val, true_end_val = sess.run([loss,pred_start,pred_end], feed_dict = {question : Q_val, context : D_val, answer_start : A_start, answer_end : A_end})\n",
    "                f1_val, em_val = evaluate()\n",
    "                print \"-\"*20\n",
    "                print \"Validation Step = \", step\n",
    "                print \"Validation F1 Score = \", f1_val\n",
    "                print \"Validation EM Score = \", em_val\n",
    "                \n",
    "            counter = counter + batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 87,  51,  27,  18,   8,  72,  26, 113,  76, 175,  17,  77, 107,\n",
       "       111,   8,  15,  96, 223,   7,  99,  45,  23,  77,   1, 205,  97,\n",
       "       138,  26,  23,  59, 101, 255,  68,  35,  15,  12,  84,   0,  26,\n",
       "        17,  40,   5,  83,   8,  12,   5,   4,  49, 169,  76,   1,  53,\n",
       "       190,  66,  42,  64,   1, 115,  19,  24,   6,  38,   0,  41, 145,\n",
       "       270,  22, 121,  45,   2,  13,   8, 101,  79,  61,  25,  83,  46,\n",
       "        24,  22, 137,  37,  86, 105, 153,  30,   8,  78,  88,  77,   2,\n",
       "         6,  46,   3,  86,  28,  40,  41,  92, 121,  18,  57,  31,  36,\n",
       "        21, 165,  89,  90,   7,   9,  11,  17,  21, 121, 155,  30,  28,\n",
       "       167, 100,  29,   3,  44,  11,  10,   9,   1,  56,  68])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_start_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 88,  52,  44,  19,  15,  72,  26, 115,  78, 179,  19,  78, 107,\n",
       "       114,  19,  15, 102, 224,   8, 100,  45,  39,  78,   1, 206,  97,\n",
       "       140,  26,  26,  68, 102, 257,  70,  36,  20,  13,  86,   2,  31,\n",
       "        18,  40,   5,  86,   9,  13,   5,   4,  49, 169,  76,   1,  53,\n",
       "       192,  66,  46,  64,   1, 123,  19,  26,   8,  38,   1,  41, 146,\n",
       "       274,  22, 123,  48,   2,  13,  10, 106,  79,  61,  26,  85,  48,\n",
       "        24,  22, 140,  43,  86, 112, 153,  31,   9,  78,  88,  82,   2,\n",
       "         6,  67,   4,  89,  28,  45,  43,  99, 122,  23,  58,  31,  38,\n",
       "        22, 166,  91,  94,   8,   9,  11,  17,  23, 136, 158,  33,  28,\n",
       "       168, 120,  31,   3,  59,  19,  13,  10,   1,  56,  68])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_end_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.99927521098731009, 1.0)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "def evaluate(context, predict_start, predict_end, answer_start, answer_end):\n",
    "    f1_scores = []\n",
    "    em_scores = []\n",
    "    for i, vector in enumerate(context):\n",
    "        prediction_tokens = vector[predict_start[i]:predict_end[i]+1]\n",
    "        ground_truth_tokens = vector[answer_start[i]:answer_end[i]+1]\n",
    "        common = Counter(prediction_tokens) & Counter(ground_truth_tokens)\n",
    "        num_same = sum(common.values())\n",
    "        if num_same == 0:\n",
    "            f1_scores.append(0)\n",
    "            continue\n",
    "        precision = 1.0 * num_same / len(prediction_tokens)\n",
    "        recall = 1.0 * num_same / len(ground_truth_tokens)\n",
    "        f1 = (2 * precision * recall) / (precision + recall)\n",
    "        em = np.min(prediction_tokens == ground_truth_tokens)\n",
    "        f1_scores.append(f1)\n",
    "        em_scores.append(em)\n",
    "    return np.mean(f1_scores), np.mean(em_scores)\n",
    "\n",
    "evaluate(context_data, answer_start_data, answer_end_data,answer_start_data, answer_end_data )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read validation and test files\n",
    "#preprocess them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
