{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset -fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(filepath,ml):\n",
    "    c = []\n",
    "    if ml == 0:\n",
    "        ml = 1000\n",
    "    with open(filepath,'r') as f:\n",
    "        for line in f:\n",
    "            line = line.replace('\\n','')\n",
    "            s = 0\n",
    "            c.append([int(line.split()[i]) for i in range(len(line.split())) if i<ml])\n",
    "    return c\n",
    "\n",
    "def final_preprocess(c):   #padding\n",
    "    max_l = max([len(i) for i in c])\n",
    "    for i in range(len(c)):\n",
    "        c[i] = c[i] + (max_l-len(c[i]))*[0]\n",
    "    return c,max_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#reading train data and preprocessing them + padding\n",
    "#pad the context and question data\n",
    "context_data,max_l_context = final_preprocess(preprocess('data/train.ids.context',600))\n",
    "question_data,max_l_question = final_preprocess(preprocess('data/train.ids.question',0))\n",
    "answer_data = preprocess('data/train.span',0)\n",
    "answer_start_data = [i[0] for i in answer_data]\n",
    "answer_end_data = [i[1] for i in answer_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data/train.ids.question', 'r') as f:\n",
    "    result = []\n",
    "    for line in f:\n",
    "        result.append(len(line.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7f7e61d1fed0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEKCAYAAADaa8itAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAGfJJREFUeJzt3XuwnPV93/H3xyLGMja2Mc6pItGKJpp4BEpwOCXkMplT\n0xoldg2T2o48uIiEQelAE6dV6krpTJ1mRlM8ie2YNDBVjA0kjrFCLqhxSExln6aZMRARk4iLqVUj\nglSB4isWrYkP/faP/SleDkfWSufZs9rV+zWzc579Ppf9fc9K+ui57LOpKiRJ6sKLRj0ASdLkMFQk\nSZ0xVCRJnTFUJEmdMVQkSZ0xVCRJnTFUJEmdMVQkSZ0xVCRJnTlt1ANYameffXatXr36mMs988wz\nnHHGGcMf0BKZpH4mqReYrH4mqRewn37333//F6rqNcda7pQLldWrV7N79+5jLjc7O8vMzMzwB7RE\nJqmfSeoFJqufSeoF7KdfkscHWc7DX5KkzhgqkqTOGCqSpM4YKpKkzgwtVJJ8KMmhJA8uMG9zkkpy\ndl9ta5K9SR5Ncmlf/cIke9q8G5Kk1U9P8rFWvzfJ6mH1IkkazDD3VG4B1s8vJjkHeAPw1321tcAG\n4Ly2zo1JlrXZNwHXAGva48g2rwa+XFXfBbwfeM9QupAkDWxooVJVfwp8aYFZ7wfeBfR/5eRlwO1V\n9WxVPQbsBS5KsgI4s6ruqd5XVN4GXN63zq1t+g7gkiN7MZKk0VjSz6kkuQw4UFV/Oe/f/5XAPX3P\n97faN9r0/PqRdZ4AqKq5JF8FXg18YYHX3QRsApiammJ2dvaYYz18+PBAy42LSepnknqByepnknoB\n+zkRSxYqSV4K/AK9Q19Lqqq2A9sBpqena5AP//ihp5PXJPUCk9XPJPUC9nMilnJP5TuBc4Ejeymr\ngL9IchFwADinb9lVrXagTc+v07fO/iSnAa8AvjjMBkZp9ZaPL1jfd/0bl3gkknR0S3ZJcVXtqapv\nr6rVVbWa3qGs76uqJ4GdwIZ2Rde59E7I31dVB4Gnk1zczpdcCdzZNrkT2Nim3wJ8sp13kSSNyDAv\nKf4o8Gngu5PsT3L10ZatqoeAHcDDwB8D11XVc232tcAH6Z28/1/AXa1+M/DqJHuBfwNsGUojkqSB\nDe3wV1W9/RjzV897vg3YtsByu4HzF6h/HXjr4kYpSeqSn6iXJHXGUJEkdcZQkSR1xlCRJHXGUJEk\ndcZQkSR1xlCRJHXGUJEkdcZQkSR1xlCRJHXGUJEkdcZQkSR1xlCRJHXGUJEkdcZQkSR1xlCRJHXG\nUJEkdcZQkSR1xlCRJHXGUJEkdcZQkSR1ZmihkuRDSQ4lebCv9stJPpvkr5L8fpJX9s3bmmRvkkeT\nXNpXvzDJnjbvhiRp9dOTfKzV702yeli9SJIGM8w9lVuA9fNqdwPnV9X3AP8T2AqQZC2wATivrXNj\nkmVtnZuAa4A17XFkm1cDX66q7wLeD7xnaJ1IkgYytFCpqj8FvjSv9omqmmtP7wFWtenLgNur6tmq\negzYC1yUZAVwZlXdU1UF3AZc3rfOrW36DuCSI3sxkqTROG2Er/1TwMfa9Ep6IXPE/lb7RpueXz+y\nzhMAVTWX5KvAq4EvzH+hJJuATQBTU1PMzs4ec3CHDx8eaLmlsnnd3IL1Qcd4svWzGJPUC0xWP5PU\nC9jPiRhJqCT598Ac8JGleL2q2g5sB5ienq6ZmZljrjM7O8sgyy2Vq7Z8fMH6vitmBlr/ZOtnMSap\nF5isfiapF7CfE7HkV38luQp4E3BFO6QFcAA4p2+xVa12gG8eIuuvP2+dJKcBrwC+OLSBS5KOaUlD\nJcl64F3Am6vq//TN2glsaFd0nUvvhPx9VXUQeDrJxe18yZXAnX3rbGzTbwE+2RdSkqQRGNrhryQf\nBWaAs5PsB95N72qv04G72zn1e6rqX1bVQ0l2AA/TOyx2XVU91zZ1Lb0ryZYDd7UHwM3AbybZS++C\ngA3D6kWSNJihhUpVvX2B8s3fYvltwLYF6ruB8xeofx1462LGKEnqlp+olyR1xlCRJHXGUJEkdcZQ\nkSR1xlCRJHXGUJEkdcZQkSR1xlCRJHXGUJEkdcZQkSR1xlCRJHXGUJEkdcZQkSR1xlCRJHXGUJEk\ndcZQkSR1xlCRJHXGUJEkdcZQkSR1xlCRJHVmaKGS5ENJDiV5sK92VpK7k3yu/XxV37ytSfYmeTTJ\npX31C5PsafNuSJJWPz3Jx1r93iSrh9WLJGkww9xTuQVYP6+2BdhVVWuAXe05SdYCG4Dz2jo3JlnW\n1rkJuAZY0x5Htnk18OWq+i7g/cB7htaJJGkgQwuVqvpT4EvzypcBt7bpW4HL++q3V9WzVfUYsBe4\nKMkK4MyquqeqCrht3jpHtnUHcMmRvRhJ0mgs9TmVqao62KafBKba9Ergib7l9rfayjY9v/68dapq\nDvgq8OrhDFuSNIjTRvXCVVVJaileK8kmYBPA1NQUs7Ozx1zn8OHDAy23VDavm1uwPugYT7Z+FmOS\neoHJ6meSegH7ORFLHSpPJVlRVQfboa1DrX4AOKdvuVWtdqBNz6/3r7M/yWnAK4AvLvSiVbUd2A4w\nPT1dMzMzxxzo7Owsgyy3VK7a8vEF6/uumFmwvnre8pvXPcd7/+wZ9l3/xq6HtuROtvdmsSapn0nq\nBeznRCz14a+dwMY2vRG4s6++oV3RdS69E/L3tUNlTye5uJ0vuXLeOke29Rbgk+28iyRpRIa2p5Lk\no8AMcHaS/cC7geuBHUmuBh4H3gZQVQ8l2QE8DMwB11XVc21T19K7kmw5cFd7ANwM/GaSvfQuCNgw\nrF5OZvP3SCRplIYWKlX19qPMuuQoy28Dti1Q3w2cv0D968BbFzNGSVK3/ES9JKkzhookqTOGiiSp\nM4aKJKkzhookqTOGiiSpMyO7TYtG42ifa5mET9pLGj33VCRJnTFUJEmdMVQkSZ3xnIpOiOdmJC3E\nPRVJUmcMFUlSZwwVSVJnDBVJUmcMFUlSZwwVSVJnDBVJUmcMFUlSZwwVSVJnDBVJUmdGEipJ/nWS\nh5I8mOSjSV6S5Kwkdyf5XPv5qr7ltybZm+TRJJf21S9MsqfNuyFJRtGPJKlnyUMlyUrgZ4Hpqjof\nWAZsALYAu6pqDbCrPSfJ2jb/PGA9cGOSZW1zNwHXAGvaY/0StiJJmmegUEmya5DacTgNWJ7kNOCl\nwP8GLgNubfNvBS5v05cBt1fVs1X1GLAXuCjJCuDMqrqnqgq4rW8dSdIIfMu7FCd5Cb1/9M9uh6OO\nHF46E1h5Ii9YVQeS/Arw18D/BT5RVZ9IMlVVB9tiTwJTbXolcE/fJva32jfa9Py6JGlEjnXr+58G\nfg74DuB+vhkqTwP/+UResIXTZcC5wFeA30nyjv5lqqqS1Ils/yivuQnYBDA1NcXs7Owx1zl8+PBA\nyy2VzevmFrX+1PJvvY1f+8idC9bXrXzFcY1nKX5nJ9t7s1iT1M8k9QL2cyK+ZahU1QeADyT5mar6\ntY5e858Aj1XV3wAk+T3gB4GnkqyoqoPt0NahtvwB4Jy+9Ve12oE2Pb++UB/bge0A09PTNTMzc8xB\nzs7OMshyS+Wqo3x/yaA2r5vjvXuO/+tz9l0xc1zjOdryXTrZ3pvFmqR+JqkXsJ8TMdC/MlX1a0l+\nEFjdv05V3XYCr/nXwMVJXkrv8NclwG7gGWAjcH37eeS/zjuB307yPnp7TGuA+6rquSRPJ7kYuBe4\nEugq+CRJJ2CgUEnym8B3Ag8Az7XykZPjx6Wq7k1yB/AXwBzwGXp7ES8DdiS5GngceFtb/qEkO4CH\n2/LXVdWRMVwL3AIsB+5qD0nSiAx6PGQaWNuuslq0qno38O555Wfp7bUstPw2YNsC9d3A+V2MSZK0\neIN+TuVB4O8NcyCSpPE36J7K2cDDSe6jt0cBQFW9eSijkiSNpUFD5ReHOQhJ0mQY9Oqv/z7sgUiS\nxt+gV399jd7VXgAvBr4NeKaqzhzWwCRJ42fQPZWXH5ludwK+DLh4WIOSJI2n475LcfX8AXDpMReW\nJJ1SBj389eN9T19E73MrXx/KiCRJY2vQq7/+Wd/0HLCP3iEwSZL+zqDnVH5y2AORJI2/Qb+ka1WS\n309yqD1+N8mqY68pSTqVDHqi/sP07hb8He3xX1tNkqS/M2iovKaqPlxVc+1xC/CaIY5LkjSGBg2V\nLyZ5R5Jl7fEO4IvDHJgkafwMGio/Re/7TZ4EDgJvAa4a0pgkSWNq0EuKfwnYWFVfBkhyFvAr9MJG\nkiRg8FD5niOBAlBVX0ryuiGNSSeR1Uf5LnpJWsigh79elORVR560PZVBA0mSdIoYNBjeC3w6ye+0\n529lga/3lSSd2gb9RP1tSXYDr2+lH6+qh4c3LEnSOBr4EFYLEYNEknRUx33r+y4keWWSO5J8Nskj\nSX4gyVlJ7k7yufaz/xzO1iR7kzya5NK++oVJ9rR5N7TvepEkjchIQgX4APDHVfVa4HuBR4AtwK6q\nWgPsas9JshbYAJwHrAduTLKsbecm4BpgTXusX8omJEnPt+ShkuQVwI8ANwNU1d9W1Vfo3Ur/1rbY\nrcDlbfoy4PaqeraqHgP2AhclWQGcWVX3VFUBt/WtI0kagVHsqZwL/A3w4SSfSfLBJGcAU1V1sC3z\nJDDVplcCT/Stv7/VVrbp+XVJ0oiM4rMmpwHfB/xMVd2b5AO0Q11HVFUlqa5eMMkmYBPA1NQUs7Oz\nx1zn8OHDAy23VDavm1vU+lPLF7+NQSzF7+xke28Wa5L6maRewH5OxChCZT+wv6rubc/voBcqTyVZ\nUVUH26GtQ23+AeCcvvVXtdqBNj2//gJVtR3YDjA9PV0zMzPHHOTs7CyDLLdUrlrkJ9s3r5vjvXuG\n/3bvu2Jm6K9xsr03izVJ/UxSL2A/J2LJD39V1ZPAE0m+u5UuoXep8k5gY6ttBO5s0zuBDUlOT3Iu\nvRPy97VDZU8nubhd9XVl3zqSpBEY1a1Wfgb4SJIXA58HfpJewO1IcjXwOL27IlNVDyXZQS945oDr\nquq5tp1rgVuA5cBd7SFJGpGRhEpVPQBMLzDrkqMsv40FbgtTVbuB87sdnSTpRI3qcyqSpAlkqEiS\nOmOoSJI6Y6hIkjpjqEiSOmOoSJI6Y6hIkjpjqEiSOmOoSJI6Y6hIkjpjqEiSOmOoSJI6Y6hIkjpj\nqEiSOmOoSJI6Y6hIkjpjqEiSOmOoSJI6Y6hIkjpjqEiSOmOoSJI6M7JQSbIsyWeS/GF7flaSu5N8\nrv18Vd+yW5PsTfJokkv76hcm2dPm3ZAko+hFktQzyj2VdwKP9D3fAuyqqjXArvacJGuBDcB5wHrg\nxiTL2jo3AdcAa9pj/dIMXZK0kJGESpJVwBuBD/aVLwNubdO3Apf31W+vqmer6jFgL3BRkhXAmVV1\nT1UVcFvfOpKkEThtRK/7q8C7gJf31aaq6mCbfhKYatMrgXv6ltvfat9o0/PrL5BkE7AJYGpqitnZ\n2WMO8PDhwwMtt1Q2r5tb1PpTyxe/jUEsxe/sZHtvFmuS+pmkXsB+TsSSh0qSNwGHqur+JDMLLVNV\nlaS6es2q2g5sB5ienq6ZmQVf9nlmZ2cZZLmlctWWjy9q/c3r5njvnuG/3fuumBn6a5xs781iTVI/\nk9QL2M+JGMWeyg8Bb07yY8BLgDOT/BbwVJIVVXWwHdo61JY/AJzTt/6qVjvQpufXJUkjsuTnVKpq\na1WtqqrV9E7Af7Kq3gHsBDa2xTYCd7bpncCGJKcnOZfeCfn72qGyp5Nc3K76urJvHUnSCIzqnMpC\nrgd2JLkaeBx4G0BVPZRkB/AwMAdcV1XPtXWuBW4BlgN3tYckaURGGipVNQvMtukvApccZbltwLYF\n6ruB84c3QknS8fAT9ZKkzhgqkqTOGCqSpM4YKpKkzhgqkqTOGCqSpM6cTJ9TEbB6kbdjkaRRck9F\nktQZQ0WS1BkPf6lTRzt8t+/6Ny7xSCSNgnsqkqTOGCqSpM4YKpKkzhgqkqTOGCqSpM4YKpKkzhgq\nkqTOGCqSpM4YKpKkzhgqkqTOLHmoJDknyaeSPJzkoSTvbPWzktyd5HPt56v61tmaZG+SR5Nc2le/\nMMmeNu+GJFnqfiRJ3zSKPZU5YHNVrQUuBq5LshbYAuyqqjXArvacNm8DcB6wHrgxybK2rZuAa4A1\n7bF+KRuRJD3fkt9QsqoOAgfb9NeSPAKsBC4DZtpitwKzwL9r9dur6lngsSR7gYuS7APOrKp7AJLc\nBlwO3LVkzWhg3+p7YrzZpDQ5RnpOJclq4HXAvcBUCxyAJ4GpNr0SeKJvtf2ttrJNz69LkkZkZLe+\nT/Iy4HeBn6uqp/tPh1RVJakOX2sTsAlgamqK2dnZY65z+PDhgZbr2uZ1c0PZ7tTy4W17sY739zyq\n92ZYJqmfSeoF7OdEjCRUknwbvUD5SFX9Xis/lWRFVR1MsgI41OoHgHP6Vl/Vagfa9Pz6C1TVdmA7\nwPT0dM3MzBxzjLOzswyyXNeuGtLXCW9eN8d795ycX5+z74qZ41p+VO/NsExSP5PUC9jPiRjF1V8B\nbgYeqar39c3aCWxs0xuBO/vqG5KcnuRceifk72uHyp5OcnHb5pV960iSRmAU/3X9IeBfAHuSPNBq\nvwBcD+xIcjXwOPA2gKp6KMkO4GF6V45dV1XPtfWuBW4BltM7Qe9JekkaoVFc/fVnwNE+T3LJUdbZ\nBmxboL4bOL+70UmSFsNP1EuSOmOoSJI6c3JeDqRTytE+GOmHIqXx456KJKkzhookqTMe/tLY2XPg\nqwt+SNTDZdLouaciSeqMoSJJ6oyHv0bkW90KXj1H+x1tXrfEA5E0MPdUJEmdMVQkSZ0xVCRJnTFU\nJEmdMVQkSZ0xVCRJnTFUJEmdMVQkSZ0xVCRJnTFUJEmd8TYtmhh+2Zc0eobKEHl/L0mnmrEPlSTr\ngQ8Ay4APVtX1Ix6STjLuwUhLZ6xDJcky4NeBfwrsB/48yc6qeni0I9M4MGyk7o11qAAXAXur6vMA\nSW4HLgMMFZ2wrg5bGk46FY17qKwEnuh7vh/4/hGNRXqeQcNp87o5rtrycUNIE2HcQ2UgSTYBm9rT\nw0keHWC1s4EvDG9US+tnJ6ifSeoFvtlP3jPqkXRiot4b7KffPxhkoXEPlQPAOX3PV7Xa81TVdmD7\n8Ww4ye6qml7c8E4ek9TPJPUCk9XPJPUC9nMixv3Dj38OrElybpIXAxuAnSMekySdssZ6T6Wq5pL8\nK+BP6F1S/KGqemjEw5KkU9ZYhwpAVf0R8EdD2PRxHS4bA5PUzyT1ApPVzyT1AvZz3FJVw34NSdIp\nYtzPqUiSTiKGygKSrE/yaJK9SbaMejzHI8mHkhxK8mBf7awkdyf5XPv5qlGO8XgkOSfJp5I8nOSh\nJO9s9bHrKclLktyX5C9bL/+x1ceul35JliX5TJI/bM/Htp8k+5LsSfJAkt2tNpb9JHllkjuSfDbJ\nI0l+YCl6MVTm6bv1y48Ca4G3J1k72lEdl1uA9fNqW4BdVbUG2NWej4s5YHNVrQUuBq5r78c49vQs\n8Pqq+l7gAmB9kosZz176vRN4pO/5uPfzj6vqgr5Lb8e1nw8Af1xVrwW+l957NPxeqspH3wP4AeBP\n+p5vBbaOelzH2cNq4MG+548CK9r0CuDRUY9xEb3dSe9eb2PdE/BS4C/o3QFibHuh99mwXcDrgT9s\ntXHuZx9w9rza2PUDvAJ4jHbefCl7cU/lhRa69cvKEY2lK1NVdbBNPwlMjXIwJyrJauB1wL2MaU/t\nUNEDwCHg7qoa216aXwXeBfy/vto491PAf0tyf7sTB4xnP+cCfwN8uB2a/GCSM1iCXgyVU0z1/osy\ndpf8JXkZ8LvAz1XV0/3zxqmnqnquqi6g9z/8i5KcP2/+2PSS5E3Aoaq6/2jLjFM/zQ+39+dH6R1q\n/ZH+mWPUz2nA9wE3VdXrgGeYd6hrWL0YKi800K1fxsxTSVYAtJ+HRjye45Lk2+gFykeq6vdaeax7\nqqqvAJ+id/5rXHv5IeDNSfYBtwOvT/JbjG8/VNWB9vMQ8Pv07oQ+jv3sB/a3PWGAO+iFzNB7MVRe\naBJv/bIT2NimN9I7LzEWkgS4GXikqt7XN2vsekrymiSvbNPL6Z0b+ixj2AtAVW2tqlVVtZre35NP\nVtU7GNN+kpyR5OVHpoE3AA8yhv1U1ZPAE0m+u5UuofeVIEPvxQ8/LiDJj9E7Vnzk1i/bRjykgSX5\nKDBD726kTwHvBv4A2AH8feBx4G1V9aVRjfF4JPlh4H8Ae/jmcftfoHdeZax6SvI9wK30/ly9CNhR\nVb+U5NWMWS/zJZkBfr6q3jSu/ST5h/T2TqB3+Oi3q2rbGPdzAfBB4MXA54GfpP25Y4i9GCqSpM54\n+EuS1BlDRZLUGUNFktQZQ0WS1BlDRZLUGUNF6lCSw0PY5gXtMvcjz38xyc93/TpSFwwV6eR3AfBj\nx1xKOgkYKtKQJPm3Sf48yV/1fXfK6vbdFr/RvlPlE+3T9ST5R23ZB5L8cpIH210dfgn4iVb/ibb5\ntUlmk3w+yc+OqEXpBQwVaQiSvAFYQ+/eURcAF/bdnHAN8OtVdR7wFeCft/qHgZ9uNzR8DqCq/hb4\nD8DHqvcdHx9ry74WuLRt/93t/mjSyBkq0nC8oT0+Q+97U15LL0wAHquqB9r0/cDqdk+wl1fVp1v9\nt4+x/Y9X1bNV9QV6NwUch9ux6xRw2qgHIE2oAP+pqv7L84q974R5tq/0HLD8BLY/fxv+XdZJwT0V\naTj+BPip9j0wJFmZ5NuPtnC7Ff7Xknx/K23om/014OVDG6nUIUNFGoKq+gS9Q1ifTrKH3vdZHCsY\nrgZ+o30z5BnAV1v9U/ROzPefqJdOSt6lWDpJJHlZVR1u01vofZf4O0c8LOm4eBxWOnm8MclWen8v\nHweuGu1wpOPnnookqTOeU5EkdcZQkSR1xlCRJHXGUJEkdcZQkSR1xlCRJHXm/wOWDCZ+fEixegAA\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7e66e96690>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(data=result).hist(bins=50)\n",
    "plt.xlabel('length')\n",
    "plt.ylabel('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(question_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "print (max_l_context)\n",
    "print (max_l_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def length(sequence):\n",
    "    used = tf.sign(tf.reduce_max(tf.abs(sequence), axis=2))\n",
    "    length = tf.reduce_sum(used, axis=1)\n",
    "    length = tf.cast(length, tf.int32)\n",
    "    #print \"sequence length tf shape:\",length.shape\n",
    "    return length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#encoder function\n",
    "def encoder(question,context,embeddings,hidden_units=200):\n",
    "    batch_size = tf.shape(question)[0]\n",
    "    #question and document encoder\n",
    "    q_embedding = tf.nn.embedding_lookup(embeddings,question)\n",
    "    d_embedding = tf.nn.embedding_lookup(embeddings,context)\n",
    "    \n",
    "    print (q_embedding.shape,\"=?,60,100\")\n",
    "    print (d_embedding.shape,\"=?,600,100\")\n",
    "    \n",
    "    lstm_enc = tf.contrib.rnn.BasicLSTMCell(hidden_units)\n",
    "    \n",
    "    with tf.variable_scope('document_encoder') as scope1:\n",
    "        document_states,_ = tf.nn.dynamic_rnn(cell=lstm_enc,\n",
    "                                              dtype=tf.float32,\n",
    "                                              inputs=d_embedding,\n",
    "                                              sequence_length=length(q_embedding),\n",
    "                                              time_major=False)\n",
    "        \n",
    "    with tf.variable_scope('question_encoder') as scope2:\n",
    "        question_states,_ = tf.nn.dynamic_rnn(cell=lstm_enc,\n",
    "                                              dtype=tf.float32,\n",
    "                                              inputs=q_embedding,\n",
    "                                              sequence_length=length(d_embedding),\n",
    "                                              time_major=False)\n",
    "\n",
    "    Wq = tf.get_variable(name=\"Wq\",shape=[hidden_units,hidden_units],initializer=tf.contrib.layers.xavier_initializer(),dtype=tf.float32)\n",
    "    bq = tf.Variable(tf.constant(0.0,shape=[hidden_units,]),dtype=tf.float32,name='bq')\n",
    "    Wq = tf.expand_dims(tf.ones([batch_size,1]), 1) * Wq\n",
    "    #question_states_new = tf.reshape(question_states,shape=[-1,hidden_units])\n",
    "    print (document_states.shape,\"=?,600,200\")\n",
    "    print (question_states.shape,\"=?,60,200\")\n",
    "    #print question_states_new.shape,\"=?,200\"\n",
    "    print (Wq.shape,\"=?,200,200\")\n",
    "    print (bq.shape,\"=200,\")\n",
    "    \n",
    "                    \n",
    "    question_states_modified_duplicate = tf.nn.tanh(tf.matmul(question_states,Wq)+bq)\n",
    "    #question_states_modified_duplicate = tf.reshape(question_states_modified,shape=[-1,int(question_states.shape[1]),hidden_units])\n",
    "    question_states_modified = tf.transpose(question_states_modified_duplicate,perm=[0,2,1]) #tf.reshape(question_states_modified,shape=[-1,hidden_units,int(question_states.shape[1])])\n",
    "    print (question_states_modified.shape,\"=?,200,60\")\n",
    "    print (question_states_modified_duplicate.shape,\"=?,60,200\")\n",
    "\n",
    "    #coattention encoder\n",
    "    \n",
    "    l = tf.matmul(document_states,question_states_modified)\n",
    "    print (l.shape,\"=?,600,60\")\n",
    "    aq = tf.nn.softmax(l)\n",
    "    ad = tf.nn.softmax(tf.transpose(l,perm=[0, 2, 1]))\n",
    "    print (aq.shape,\"=?,600,60\")\n",
    "    print (ad.shape,\"=?,60,600\")\n",
    "    \n",
    "    cq = tf.matmul(tf.transpose(aq,perm=[0,2,1]),document_states)\n",
    "    print (cq.shape,\"=?,60,200\")\n",
    "    print (question_states_modified_duplicate.shape,\"=?,60,200\")\n",
    "    qcq = tf.concat([question_states_modified_duplicate,cq],2)\n",
    "    print (qcq.shape,\"=?,60,400\")\n",
    "    cd = (tf.matmul(tf.transpose(ad,perm=[0,2,1]),qcq))\n",
    "    print (cd.shape,\"=?,600,400\")\n",
    "    dcd = tf.concat([document_states,cd],axis=2)\n",
    "    print (dcd.shape,\"=?,600,600\")\n",
    "    \n",
    "    with tf.variable_scope('coattention'):\n",
    "        u_lstm_fw = tf.contrib.rnn.BasicLSTMCell(hidden_units)  #bi-lstm\n",
    "        u_lstm_bw = tf.contrib.rnn.BasicLSTMCell(hidden_units)\n",
    "        u_states,_ = tf.nn.bidirectional_dynamic_rnn(cell_bw=u_lstm_bw,cell_fw=u_lstm_fw,dtype=tf.float32,inputs=dcd,time_major=False,sequence_length=length(dcd))\n",
    "    encoder_states = tf.concat(u_states,2)\n",
    "    print (encoder_states.shape)\n",
    "    return encoder_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#decoder function\n",
    "def decoder(knowledge_reps,hidden_units = 200):\n",
    "    #randomly initialise s and e\n",
    "    batch_size = tf.shape(knowledge_reps)[0]\n",
    "    #print batch_size\n",
    "    pool = 16\n",
    "    e = np.random.randint(max_l_context) + 1\n",
    "    s = np.random.randint(e)\n",
    "    sv = tf.tile([s],[batch_size])\n",
    "    ev = tf.tile([e],[batch_size])\n",
    "\n",
    "    #lstm cell\n",
    "    #with tf.variable_scope('lstm_dec') as scope_dec:\n",
    "    lstm_dec = tf.contrib.rnn.LSTMCell(hidden_units)\n",
    "    ch = lstm_dec.zero_state(batch_size,dtype=tf.float32)\n",
    "    hi,ci = ch\n",
    "    \n",
    "    \n",
    "    with tf.variable_scope('hmn1') as scope1:\n",
    "        wd = tf.get_variable(name=\"wd\",shape=[hidden_units,5*hidden_units],initializer=tf.contrib.layers.xavier_initializer(),dtype=tf.float32)\n",
    "        w1 = tf.get_variable(name=\"w1\",shape=[pool*hidden_units,3*hidden_units],initializer=tf.contrib.layers.xavier_initializer(),dtype=tf.float32)\n",
    "        w2 = tf.get_variable(name=\"w2\",shape=[pool*hidden_units,hidden_units],initializer=tf.contrib.layers.xavier_initializer(),dtype=tf.float32)\n",
    "        w3 = tf.get_variable(name=\"w3\",shape=[pool,2*hidden_units],initializer=tf.contrib.layers.xavier_initializer(),dtype=tf.float32)\n",
    "    \n",
    "    with tf.variable_scope('hmn2') as scope2:\n",
    "        wd = tf.get_variable(name=\"wd\",shape=[hidden_units,5*hidden_units],initializer=tf.contrib.layers.xavier_initializer(),dtype=tf.float32)\n",
    "        w1 = tf.get_variable(name=\"w1\",shape=[pool*hidden_units,3*hidden_units],initializer=tf.contrib.layers.xavier_initializer(),dtype=tf.float32)\n",
    "        w2 = tf.get_variable(name=\"w2\",shape=[pool*hidden_units,hidden_units],initializer=tf.contrib.layers.xavier_initializer(),dtype=tf.float32)\n",
    "        w3 = tf.get_variable(name=\"w3\",shape=[pool,2*hidden_units],initializer=tf.contrib.layers.xavier_initializer(),dtype=tf.float32)\n",
    "\n",
    "        \n",
    "    #loop 4 times to call lstm cell to:\n",
    "    for i in range(4):\n",
    "        #concatenate u_s and u_e\n",
    "        u_s = tf.gather_nd(params=knowledge_reps,indices=tf.stack([tf.range(batch_size,dtype=tf.int32),sv],axis=1))\n",
    "        u_e = tf.gather_nd(params=knowledge_reps,indices=tf.stack([tf.range(batch_size,dtype=tf.int32),ev],axis=1))\n",
    "        usue = tf.concat([u_s,u_e],axis=1)\n",
    "        print (i,usue.shape,hi.shape)\n",
    "        #calculate hi\n",
    "         \n",
    "        with tf.variable_scope(\"hmn1\",reuse=True) as scope1:\n",
    "            sv,hmns_output = hmn(knowledge_reps,hi,u_s,u_e,hidden_units,pool)#loop over the document length times to obtain alpha t using HNM function\n",
    "        with tf.variable_scope(\"hmn2\",reuse=True) as scope2:\n",
    "            ev,hmne_output = hmn(knowledge_reps,hi,u_s,u_e,hidden_units,pool)#loop over the document length times to obtain beta t using HNM function\n",
    "        \n",
    "        hi,ch = lstm_dec(inputs=usue,state=ch) \n",
    "        \n",
    "    return sv,ev,hmns_output,hmne_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hmn(kr,hs,us,ue,hidden_units,pool=16):\n",
    "    \n",
    "    #print \"kr\",kr.shape\n",
    "    #calculate r\n",
    "    wd = tf.get_variable(name=\"wd\",shape=[hidden_units,5*hidden_units],initializer=tf.contrib.layers.xavier_initializer(),dtype=tf.float32)\n",
    "    x = tf.concat([hs,us,ue],axis=1)\n",
    "    r = tf.nn.tanh(tf.matmul(x,tf.transpose(wd)))\n",
    "    #print r.shape\n",
    "\n",
    "    #calculate mt1\n",
    "    r1 = tf.expand_dims(tf.ones([int(kr.shape[1]),1]), 1) * r\n",
    "    r1 = tf.reshape(r1,[-1,hidden_units])\n",
    "    kr1 = tf.reshape(kr,[-1,2*hidden_units])\n",
    "    krr1 = tf.concat([kr1,r1],axis=1)\n",
    "    w1 = tf.get_variable(name=\"w1\",shape=[pool*hidden_units,3*hidden_units],initializer=tf.contrib.layers.xavier_initializer(),dtype=tf.float32)\n",
    "    b1 = tf.Variable(tf.constant(0.0,shape=[pool*hidden_units,]),dtype=tf.float32)\n",
    "    x1 = tf.matmul(krr1,tf.transpose(w1))+b1\n",
    "    x1 = tf.reshape(x1,[-1,pool])\n",
    "    x1 = tf.reduce_max(x1,axis=1)\n",
    "    m1 = tf.reshape(x1,[-1,hidden_units])\n",
    "    #print m1.shape\n",
    "    \n",
    "    #calculate mt2\n",
    "    w2 = tf.get_variable(name=\"w2\",shape=[pool*hidden_units,hidden_units],initializer=tf.contrib.layers.xavier_initializer(),dtype=tf.float32)\n",
    "    b2 = tf.Variable(tf.constant(0.0,shape=[pool*hidden_units,]),dtype=tf.float32)\n",
    "    x2 = tf.matmul(m1,tf.transpose(w2))+b2\n",
    "    x2 = tf.reshape(x2,[-1,pool])\n",
    "    x2 = tf.reduce_max(x2,axis=1)\n",
    "    m2 = tf.reshape(x2,[-1,hidden_units])\n",
    "    #print m2.shape\n",
    "    \n",
    "    #max\n",
    "    m1m2 = tf.concat([m1,m2],axis=1)\n",
    "    #print \"m1m2\",m1m2.shape\n",
    "    w3 = tf.get_variable(name=\"w3\",shape=[pool,2*hidden_units],initializer=tf.contrib.layers.xavier_initializer(),dtype=tf.float32)\n",
    "    b3 = tf.Variable(tf.constant(0.0,shape=[pool,]),dtype=tf.float32)\n",
    "    x3 = tf.matmul(m1m2,tf.transpose(w3))+b3\n",
    "    #print x3.shape\n",
    "    x3 = tf.reduce_max(x3,axis=1)\n",
    "    #print x3.shape\n",
    "    x3 = tf.reshape(x3,[-1,int(kr.shape[1])])\n",
    "    #print \"x3\",x3.shape\n",
    "    #argmax\n",
    "    output = tf.argmax(x3,axis=1)\n",
    "    output = tf.cast(output,dtype=tf.int32)\n",
    "    \n",
    "    return output,x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read embedding file\n",
    "embedding_array = np.load('data/glove.trimmed.100.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.52058829, -0.51654186,  0.27968494, -1.81354095, -0.24410476,\n",
       "       -0.68052369, -0.00260126, -1.15966041,  0.13565797, -2.03933159,\n",
       "        1.39574077, -0.41010746,  0.78249643, -0.03234985,  1.49243316,\n",
       "        0.58828367, -0.12553187,  2.22018055, -0.45500756,  0.89039387,\n",
       "       -0.18749341,  0.1809392 ,  0.29886465, -0.24914736, -0.49023885,\n",
       "       -1.01622756,  1.8752643 ,  0.44214767,  1.33379188, -1.34961692,\n",
       "       -0.01415288, -0.59999874, -0.81665375,  2.37627875, -0.4235163 ,\n",
       "        0.57595554,  0.59935966,  0.02639429, -0.26178128,  0.4963044 ,\n",
       "        1.88299358, -0.46125415,  0.6598317 ,  2.18697996, -1.18201243,\n",
       "       -1.56485642,  0.71330753,  0.43130444,  0.24754809,  1.52875936,\n",
       "        0.12049194,  1.81434007,  0.11948352, -0.17062094,  0.26578507,\n",
       "       -0.38349847,  1.14144629,  1.74730465,  0.12359092, -0.68782479,\n",
       "       -0.71124553,  0.11059589, -1.03285808,  0.62593014, -0.68293404,\n",
       "        0.45794549, -1.84091036,  1.27705293, -0.24747408,  0.10791822,\n",
       "        0.74738734,  0.33532065, -0.21005892,  0.52853634, -1.82094303,\n",
       "       -0.29553369,  1.88826883,  1.41438938,  1.16707241,  1.24758589,\n",
       "        0.10214536, -0.44961063,  1.78224884, -0.85140106, -0.6694391 ,\n",
       "        0.7387805 , -2.2642288 , -1.09590889,  1.15175444,  0.49601925,\n",
       "       -1.26474121,  0.74908335,  0.39721525, -0.68880461, -0.10933572,\n",
       "        0.31228823,  2.57939613, -0.1654663 ,  0.17701885,  2.5159267 ])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_array['glove'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TensorShape([Dimension(None), Dimension(60), Dimension(100)]), '=?,60,100')\n",
      "(TensorShape([Dimension(None), Dimension(600), Dimension(100)]), '=?,600,100')\n",
      "(TensorShape([Dimension(None), Dimension(600), Dimension(200)]), '=?,600,200')\n",
      "(TensorShape([Dimension(None), Dimension(60), Dimension(200)]), '=?,60,200')\n",
      "(TensorShape([Dimension(None), Dimension(200), Dimension(200)]), '=?,200,200')\n",
      "(TensorShape([Dimension(200)]), '=200,')\n",
      "(TensorShape([Dimension(None), Dimension(200), Dimension(60)]), '=?,200,60')\n",
      "(TensorShape([Dimension(None), Dimension(60), Dimension(200)]), '=?,60,200')\n",
      "(TensorShape([Dimension(None), Dimension(600), Dimension(60)]), '=?,600,60')\n",
      "(TensorShape([Dimension(None), Dimension(600), Dimension(60)]), '=?,600,60')\n",
      "(TensorShape([Dimension(None), Dimension(60), Dimension(600)]), '=?,60,600')\n",
      "(TensorShape([Dimension(None), Dimension(60), Dimension(200)]), '=?,60,200')\n",
      "(TensorShape([Dimension(None), Dimension(60), Dimension(200)]), '=?,60,200')\n",
      "(TensorShape([Dimension(None), Dimension(60), Dimension(400)]), '=?,60,400')\n",
      "(TensorShape([Dimension(None), Dimension(600), Dimension(400)]), '=?,600,400')\n",
      "(TensorShape([Dimension(None), Dimension(600), Dimension(600)]), '=?,600,600')\n",
      "(?, 600, 400)\n",
      "decoder starts\n",
      "(0, TensorShape([Dimension(None), Dimension(800)]), TensorShape([Dimension(None), Dimension(200)]))\n",
      "(1, TensorShape([Dimension(None), Dimension(800)]), TensorShape([Dimension(None), Dimension(200)]))\n",
      "(2, TensorShape([Dimension(None), Dimension(800)]), TensorShape([Dimension(None), Dimension(200)]))\n",
      "(3, TensorShape([Dimension(None), Dimension(800)]), TensorShape([Dimension(None), Dimension(200)]))\n"
     ]
    }
   ],
   "source": [
    "## create placeholders\n",
    "tf.reset_default_graph()\n",
    "hidden_units = 200\n",
    "question = tf.placeholder(dtype=tf.int32,shape=[None,max_l_question])\n",
    "context = tf.placeholder(dtype=tf.int32,shape=[None,max_l_context])\n",
    "answer_start = tf.placeholder(dtype=tf.int32,shape=[None])\n",
    "answer_end = tf.placeholder(dtype=tf.int32,shape=[None])\n",
    "embeddings = tf.constant(embedding_array['glove'],dtype=tf.float32)\n",
    "\n",
    "encoder_states = encoder(question,context,embeddings)\n",
    "print (\"decoder starts\")\n",
    "decoder_output_start, decoder_output_end, hmns_output, hmne_output = decoder(encoder_states)\n",
    "\n",
    "## add loss\n",
    "l1 = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=answer_start,logits=hmns_output)\n",
    "l2 = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=answer_end,logits=hmne_output)\n",
    "loss = l1 + l2\n",
    "\n",
    "# print \"hmns_output.shape: \",hmns_output.shape\n",
    "# ## EM accuracy\n",
    "pred_start = tf.argmax(hmns_output, 1)\n",
    "# pred_start_v = tf.expand_dims(pred_start, 1)\n",
    "pred_end = tf.argmax(hmne_output, 1)\n",
    "# pred_end_v = tf.expand_dims(pred_end, 1)\n",
    "# pred = tf.gather_nd(question, )\n",
    "\n",
    "# answer_start_v = tf.expand_dims(answer_start, 1)\n",
    "# answer_end_v = tf.expand_dims(answer_end, 1)\n",
    "\n",
    "# print \"question.shape: \",question.shape\n",
    "# print \"pred_start.shape: \",pred_start.shape\n",
    "# print \"answers.shape\",tf.gather_nd(question, answer_start_v).shape\n",
    "# print \"tf.equal shape: \",tf.equal(tf.gather_nd(context, pred_start_v), tf.gather_nd(context, answer_start_v)).shape\n",
    "# EM_acc = tf.logical_and(tf.equal(tf.gather_nd(context, pred_start_v), tf.gather_nd(context, answer_start_v)), \n",
    "#                         tf.equal(tf.gather_nd(context, pred_end_v), tf.gather_nd(context, answer_end_v))\n",
    "#                        )\n",
    "# EM_acc = tf.cast(EM_acc, tf.int32)\n",
    "# EM_acc = tf.reduce_mean(tf.reduce_min(EM_acc, axis=1))\n",
    "# print \"EM_acc.shape: \",EM_acc.shape\n",
    "\n",
    "## F1 Score\n",
    "\n",
    "\n",
    "## add optimizer\n",
    "train_op = tf.train.AdamOptimizer(0.0001).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.99927521098731009, 1.0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "def evaluate(context, predict_start, predict_end, answer_start, answer_end):\n",
    "    f1_scores = []\n",
    "    em_scores = []\n",
    "    for i, vector in enumerate(context):\n",
    "        prediction_tokens = vector[predict_start[i]:predict_end[i]+1]\n",
    "        ground_truth_tokens = vector[answer_start[i]:answer_end[i]+1]\n",
    "        common = Counter(prediction_tokens) & Counter(ground_truth_tokens)\n",
    "        num_same = sum(common.values())\n",
    "        if num_same == 0:\n",
    "            f1_scores.append(0)\n",
    "            continue\n",
    "        precision = 1.0 * num_same / len(prediction_tokens)\n",
    "        recall = 1.0 * num_same / len(ground_truth_tokens)\n",
    "        f1 = (2 * precision * recall) / (precision + recall)\n",
    "        em = np.min(prediction_tokens == ground_truth_tokens)\n",
    "        f1_scores.append(f1)\n",
    "        em_scores.append(em)\n",
    "    return np.mean(f1_scores), np.mean(em_scores)\n",
    "\n",
    "evaluate(context_data, answer_start_data, answer_end_data,answer_start_data, answer_end_data )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#initialise variables and train\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tristan/anaconda3/envs/nlp-final/lib/python2.7/site-packages/ipykernel_launcher.py:16: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "('step = ', 0)\n",
      "('F1 Score = ', 0.013477533159808906)\n",
      "('EM score = ', 0.0)\n",
      "--------------------\n",
      "('Validation Step = ', 0)\n",
      "('Validation F1 Score = ', 0.013874458874458874)\n",
      "('Validation EM Score = ', 0.0)\n",
      "====================\n",
      "('step = ', 1)\n",
      "('F1 Score = ', 0.024271191615231492)\n",
      "('EM score = ', 0.0)\n",
      "====================\n",
      "('step = ', 2)\n",
      "('F1 Score = ', 0.035479604137692369)\n",
      "('EM score = ', 0.0)\n",
      "====================\n",
      "('step = ', 3)\n",
      "('F1 Score = ', 0.018645478351660416)\n",
      "('EM score = ', 0.0)\n",
      "====================\n",
      "('step = ', 4)\n",
      "('F1 Score = ', 0.033811225671104707)\n",
      "('EM score = ', 0.0)\n",
      "====================\n",
      "('step = ', 5)\n",
      "('F1 Score = ', 0.01599798175392279)\n",
      "('EM score = ', 0.0)\n",
      "====================\n",
      "('step = ', 6)\n",
      "('F1 Score = ', 0.016229407806783003)\n",
      "('EM score = ', 0.0)\n",
      "====================\n",
      "('step = ', 7)\n",
      "('F1 Score = ', 0.014736149267399268)\n",
      "('EM score = ', 0.0)\n",
      "====================\n",
      "('step = ', 8)\n",
      "('F1 Score = ', 0.0095703125000000007)\n",
      "('EM score = ', 0.0)\n",
      "====================\n",
      "('step = ', 9)\n",
      "('F1 Score = ', 0.019702722797798038)\n",
      "('EM score = ', 0.0)\n",
      "====================\n",
      "('step = ', 10)\n",
      "('F1 Score = ', 0.017126921410326582)\n",
      "('EM score = ', 0.0)\n",
      "====================\n",
      "('step = ', 11)\n",
      "('F1 Score = ', 0.008055132972729322)\n",
      "('EM score = ', 0.0)\n",
      "====================\n",
      "('step = ', 12)\n",
      "('F1 Score = ', 0.012147141053391052)\n",
      "('EM score = ', 0.0)\n",
      "====================\n",
      "('step = ', 13)\n",
      "('F1 Score = ', 0.015731564852658603)\n",
      "('EM score = ', 0.0)\n",
      "====================\n",
      "('step = ', 14)\n",
      "('F1 Score = ', 0.016396949404761905)\n",
      "('EM score = ', 0.0)\n",
      "====================\n",
      "('step = ', 15)\n",
      "('F1 Score = ', 0.02649915188977689)\n",
      "('EM score = ', 0.0)\n",
      "====================\n",
      "('step = ', 16)\n",
      "('F1 Score = ', 0.031878040371286852)\n",
      "('EM score = ', 0.0)\n",
      "====================\n",
      "('step = ', 17)\n",
      "('F1 Score = ', 0.031796120845151016)\n",
      "('EM score = ', 0.0)\n",
      "====================\n",
      "('step = ', 18)\n",
      "('F1 Score = ', 0.030169557690116901)\n",
      "('EM score = ', 0.0)\n",
      "====================\n",
      "('step = ', 19)\n",
      "('F1 Score = ', 0.024659309281588021)\n",
      "('EM score = ', 0.0)\n",
      "====================\n",
      "('step = ', 20)\n",
      "('F1 Score = ', 0.042221062069165788)\n",
      "('EM score = ', 0.0)\n",
      "====================\n",
      "('step = ', 21)\n",
      "('F1 Score = ', 0.045072492027612474)\n",
      "('EM score = ', 0.0625)\n",
      "====================\n",
      "('step = ', 22)\n",
      "('F1 Score = ', 0.044552878664539372)\n",
      "('EM score = ', 0.0)\n",
      "====================\n",
      "('step = ', 23)\n",
      "('F1 Score = ', 0.039067353704302241)\n",
      "('EM score = ', 0.083333333333333329)\n",
      "====================\n",
      "('step = ', 24)\n",
      "('F1 Score = ', 0.045003780941280942)\n",
      "('EM score = ', 0.0)\n",
      "====================\n",
      "('step = ', 25)\n",
      "('F1 Score = ', 0.056128394618260136)\n",
      "('EM score = ', 0.0)\n",
      "====================\n",
      "('step = ', 26)\n",
      "('F1 Score = ', 0.057763474205006465)\n",
      "('EM score = ', 0.0)\n",
      "====================\n",
      "('step = ', 27)\n",
      "('F1 Score = ', 0.037495594454887218)\n",
      "('EM score = ', 0.0)\n",
      "====================\n",
      "('step = ', 28)\n",
      "('F1 Score = ', 0.04369972475441225)\n",
      "('EM score = ', 0.0)\n",
      "====================\n",
      "('step = ', 29)\n",
      "('F1 Score = ', 0.055942921117553474)\n",
      "('EM score = ', 0.041666666666666664)\n",
      "====================\n",
      "('step = ', 30)\n",
      "('F1 Score = ', 0.075099981761603846)\n",
      "('EM score = ', 0.10526315789473684)\n",
      "====================\n",
      "('step = ', 31)\n",
      "('F1 Score = ', 0.084075395390050572)\n",
      "('EM score = ', 0.090909090909090912)\n",
      "====================\n",
      "('step = ', 32)\n",
      "('F1 Score = ', 0.052465098558848566)\n",
      "('EM score = ', 0.125)\n",
      "====================\n",
      "('step = ', 33)\n",
      "('F1 Score = ', 0.039689585588023088)\n",
      "('EM score = ', 0.076923076923076927)\n",
      "====================\n",
      "('step = ', 34)\n",
      "('F1 Score = ', 0.079002440319076342)\n",
      "('EM score = ', 0.13636363636363635)\n",
      "====================\n",
      "('step = ', 35)\n",
      "('F1 Score = ', 0.032134372389306602)\n",
      "('EM score = ', 0.0)\n",
      "====================\n",
      "('step = ', 36)\n",
      "('F1 Score = ', 0.080674460773144982)\n",
      "('EM score = ', 0.13636363636363635)\n",
      "====================\n",
      "('step = ', 37)\n",
      "('F1 Score = ', 0.053657134755925075)\n",
      "('EM score = ', 0.0625)\n",
      "====================\n",
      "('step = ', 38)\n",
      "('F1 Score = ', 0.035567627948742075)\n",
      "('EM score = ', 0.071428571428571425)\n",
      "====================\n",
      "('step = ', 39)\n",
      "('F1 Score = ', 0.040449668204602419)\n",
      "('EM score = ', 0.15384615384615385)\n",
      "====================\n",
      "('step = ', 40)\n",
      "('F1 Score = ', 0.067830064900377407)\n",
      "('EM score = ', 0.086956521739130432)\n",
      "====================\n",
      "('step = ', 41)\n",
      "('F1 Score = ', 0.063333152653921948)\n",
      "('EM score = ', 0.052631578947368418)\n",
      "====================\n",
      "('step = ', 42)\n",
      "('F1 Score = ', 0.043373394864583095)\n",
      "('EM score = ', 0.052631578947368418)\n",
      "====================\n",
      "('step = ', 43)\n",
      "('F1 Score = ', 0.066545517631645679)\n",
      "('EM score = ', 0.050000000000000003)\n",
      "====================\n",
      "('step = ', 44)\n",
      "('F1 Score = ', 0.039111820629205402)\n",
      "('EM score = ', 0.071428571428571425)\n",
      "====================\n",
      "('step = ', 45)\n",
      "('F1 Score = ', 0.062249288302277425)\n",
      "('EM score = ', 0.055555555555555552)\n",
      "====================\n",
      "('step = ', 46)\n",
      "('F1 Score = ', 0.074823279092338685)\n",
      "('EM score = ', 0.043478260869565216)\n",
      "====================\n",
      "('step = ', 47)\n",
      "('F1 Score = ', 0.056660566552769097)\n",
      "('EM score = ', 0.041666666666666664)\n",
      "====================\n",
      "('step = ', 48)\n",
      "('F1 Score = ', 0.053891414442359564)\n",
      "('EM score = ', 0.0)\n",
      "====================\n",
      "('step = ', 49)\n",
      "('F1 Score = ', 0.055599141063894901)\n",
      "('EM score = ', 0.041666666666666664)\n",
      "====================\n",
      "('step = ', 50)\n",
      "('F1 Score = ', 0.070750032349896477)\n",
      "('EM score = ', 0.13636363636363635)\n",
      "====================\n",
      "('step = ', 51)\n",
      "('F1 Score = ', 0.060649611379327791)\n",
      "('EM score = ', 0.043478260869565216)\n",
      "====================\n",
      "('step = ', 52)\n",
      "('F1 Score = ', 0.065147214390690655)\n",
      "('EM score = ', 0.0)\n",
      "====================\n",
      "('step = ', 53)\n",
      "('F1 Score = ', 0.067717085857916637)\n",
      "('EM score = ', 0.033333333333333333)\n",
      "====================\n",
      "('step = ', 54)\n",
      "('F1 Score = ', 0.089340981230944347)\n",
      "('EM score = ', 0.03125)\n",
      "====================\n",
      "('step = ', 55)\n",
      "('F1 Score = ', 0.037469001567811785)\n",
      "('EM score = ', 0.0)\n",
      "====================\n",
      "('step = ', 56)\n",
      "('F1 Score = ', 0.063046032225356916)\n",
      "('EM score = ', 0.043478260869565216)\n",
      "====================\n",
      "('step = ', 57)\n",
      "('F1 Score = ', 0.07688697671414263)\n",
      "('EM score = ', 0.037037037037037035)\n"
     ]
    }
   ],
   "source": [
    "#session run train\n",
    "validation_size = 100\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    batch_size = 128\n",
    "    for epocs in range(100):\n",
    "        counter = 0\n",
    "        for steps in range(318):\n",
    "            question_batch = np.array(question_data[counter:(counter+batch_size)])\n",
    "            context_batch = np.array(context_data[counter:(counter+batch_size)])\n",
    "            answer_start_batch = np.array(answer_start_data[counter:(counter+batch_size)])\n",
    "            answer_end_batch = np.array(answer_end_data[counter:(counter+batch_size)])\n",
    "            \n",
    "            _, pred_start_batch, pred_end_batch = sess.run([train_op, pred_start, pred_end], feed_dict = {question : question_batch, context : context_batch, answer_start : answer_start_batch, answer_end : answer_end_batch})\n",
    "            f1, em = evaluate(context_batch, pred_start_batch,pred_end_batch, answer_start_batch, answer_end_batch)\n",
    "            print (\"=\" * 20)\n",
    "            print (\"step = \", steps)\n",
    "            print (\"F1 Score = \", f1)\n",
    "            print (\"EM score = \", em)\n",
    "                \n",
    "            if steps % 100 == 0:\n",
    "                Q_val = np.array(question_data[-validation_size:])\n",
    "                D_val = np.array(context_data[-validation_size:])\n",
    "                A_start = np.array(answer_start_data[-validation_size:])\n",
    "                A_end = np.array(answer_end_data[-validation_size:])\n",
    "                loss_val, pred_start_val, pred_end_val = sess.run([loss,pred_start,pred_end], feed_dict = {question : Q_val, context : D_val, answer_start : A_start, answer_end : A_end})\n",
    "                f1_val, em_val = evaluate(D_val,pred_start_val,pred_end_val, A_start,A_end)\n",
    "                print (\"-\"*20)\n",
    "                print (\"Validation Step = \", steps)\n",
    "                print (\"Validation F1 Score = \", f1_val)\n",
    "                print (\"Validation EM Score = \", em_val)\n",
    "                \n",
    "            counter = counter + batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read validation and test files\n",
    "#preprocess them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
